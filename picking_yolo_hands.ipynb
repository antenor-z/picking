{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.2.18-py3-none-any.whl.metadata (40 kB)\n",
      "     ---------------------------------------- 0.0/40.7 kB ? eta -:--:--\n",
      "     ------------------------------ --------- 30.7/40.7 kB 1.3 MB/s eta 0:00:01\n",
      "     -------------------------------------- 40.7/40.7 kB 483.4 kB/s eta 0:00:00\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in d:\\puc\\topicos_ciencia_dados_visaocomputacional\\picking\\.venv\\lib\\site-packages (from ultralytics) (3.9.0)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in d:\\puc\\topicos_ciencia_dados_visaocomputacional\\picking\\.venv\\lib\\site-packages (from ultralytics) (4.9.0.80)\n",
      "Requirement already satisfied: pillow>=7.1.2 in d:\\puc\\topicos_ciencia_dados_visaocomputacional\\picking\\.venv\\lib\\site-packages (from ultralytics) (10.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in d:\\puc\\topicos_ciencia_dados_visaocomputacional\\picking\\.venv\\lib\\site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in d:\\puc\\topicos_ciencia_dados_visaocomputacional\\picking\\.venv\\lib\\site-packages (from ultralytics) (2.31.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in d:\\puc\\topicos_ciencia_dados_visaocomputacional\\picking\\.venv\\lib\\site-packages (from ultralytics) (1.13.0)\n",
      "Requirement already satisfied: torch>=1.8.0 in d:\\puc\\topicos_ciencia_dados_visaocomputacional\\picking\\.venv\\lib\\site-packages (from ultralytics) (2.3.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in d:\\puc\\topicos_ciencia_dados_visaocomputacional\\picking\\.venv\\lib\\site-packages (from ultralytics) (0.18.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in d:\\puc\\topicos_ciencia_dados_visaocomputacional\\picking\\.venv\\lib\\site-packages (from ultralytics) (4.66.4)\n",
      "Requirement already satisfied: psutil in d:\\puc\\topicos_ciencia_dados_visaocomputacional\\picking\\.venv\\lib\\site-packages (from ultralytics) (5.9.8)\n",
      "Collecting py-cpuinfo (from ultralytics)\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Requirement already satisfied: thop>=0.1.1 in d:\\puc\\topicos_ciencia_dados_visaocomputacional\\picking\\.venv\\lib\\site-packages (from ultralytics) (0.1.1.post2209072238)\n",
      "Requirement already satisfied: pandas>=1.1.4 in d:\\puc\\topicos_ciencia_dados_visaocomputacional\\picking\\.venv\\lib\\site-packages (from ultralytics) (2.2.2)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in d:\\puc\\topicos_ciencia_dados_visaocomputacional\\picking\\.venv\\lib\\site-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\puc\\topicos_ciencia_dados_visaocomputacional\\picking\\.venv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\puc\\topicos_ciencia_dados_visaocomputacional\\picking\\.venv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\puc\\topicos_ciencia_dados_visaocomputacional\\picking\\.venv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\puc\\topicos_ciencia_dados_visaocomputacional\\picking\\.venv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
      "Requirement already satisfied: numpy>=1.23 in d:\\puc\\topicos_ciencia_dados_visaocomputacional\\picking\\.venv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\puc\\topicos_ciencia_dados_visaocomputacional\\picking\\.venv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\puc\\topicos_ciencia_dados_visaocomputacional\\picking\\.venv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\puc\\topicos_ciencia_dados_visaocomputacional\\picking\\.venv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\puc\\topicos_ciencia_dados_visaocomputacional\\picking\\.venv\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\puc\\topicos_ciencia_dados_visaocomputacional\\picking\\.venv\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\puc\\topicos_ciencia_dados_visaocomputacional\\picking\\.venv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\puc\\topicos_ciencia_dados_visaocomputacional\\picking\\.venv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\puc\\topicos_ciencia_dados_visaocomputacional\\picking\\.venv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\puc\\topicos_ciencia_dados_visaocomputacional\\picking\\.venv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2024.2.2)\n",
      "Requirement already satisfied: filelock in d:\\puc\\topicos_ciencia_dados_visaocomputacional\\picking\\.venv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in d:\\puc\\topicos_ciencia_dados_visaocomputacional\\picking\\.venv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.11.0)\n",
      "Requirement already satisfied: sympy in d:\\puc\\topicos_ciencia_dados_visaocomputacional\\picking\\.venv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
      "Requirement already satisfied: networkx in d:\\puc\\topicos_ciencia_dados_visaocomputacional\\picking\\.venv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
      "Requirement already satisfied: jinja2 in d:\\puc\\topicos_ciencia_dados_visaocomputacional\\picking\\.venv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in d:\\puc\\topicos_ciencia_dados_visaocomputacional\\picking\\.venv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2024.5.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in d:\\puc\\topicos_ciencia_dados_visaocomputacional\\picking\\.venv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2021.4.0)\n",
      "Requirement already satisfied: colorama in d:\\puc\\topicos_ciencia_dados_visaocomputacional\\picking\\.venv\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: intel-openmp==2021.* in d:\\puc\\topicos_ciencia_dados_visaocomputacional\\picking\\.venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.8.0->ultralytics) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in d:\\puc\\topicos_ciencia_dados_visaocomputacional\\picking\\.venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.8.0->ultralytics) (2021.12.0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\puc\\topicos_ciencia_dados_visaocomputacional\\picking\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\puc\\topicos_ciencia_dados_visaocomputacional\\picking\\.venv\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in d:\\puc\\topicos_ciencia_dados_visaocomputacional\\picking\\.venv\\lib\\site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Downloading ultralytics-8.2.18-py3-none-any.whl (757 kB)\n",
      "   ---------------------------------------- 0.0/757.2 kB ? eta -:--:--\n",
      "   --------------------------------------  747.5/757.2 kB 15.7 MB/s eta 0:00:01\n",
      "   --------------------------------------- 757.2/757.2 kB 15.9 MB/s eta 0:00:00\n",
      "Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Installing collected packages: py-cpuinfo, ultralytics\n",
      "Successfully installed py-cpuinfo-9.0.0 ultralytics-8.2.18\n"
     ]
    }
   ],
   "source": [
    "from yolov9.detect import run as run_yolo_detect\n",
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import Tk, simpledialog\n",
    "import mediapipe as mp\n",
    "import threading\n",
    "import json\n",
    "import cv2\n",
    "import json\n",
    "import time\n",
    "\n",
    "TOP_BORDER_HEIGHT = 80\n",
    "CONFIG_PATH = \"config-example.json\"\n",
    "CAM_NUMBER = 0\n",
    "\n",
    "new_object = None\n",
    "def get_new_object(rect_start, rect_end):\n",
    "    global new_object\n",
    "    root = Tk()\n",
    "    root.withdraw()\n",
    "    new_object_name = simpledialog.askstring(\"Novo objeto\", \"Escolha um nome:\")\n",
    "    root.destroy()\n",
    "    new_object = {\n",
    "        \"name\": new_object_name,\n",
    "        \"point_1\": [rect_start[0], rect_start[1] - TOP_BORDER_HEIGHT], \n",
    "        \"point_2\": [rect_end[0], rect_end[1] - TOP_BORDER_HEIGHT]\n",
    "    }\n",
    "\n",
    "def mid_point(acc_cx, acc_cy):\n",
    "    avg_cx = int(sum(acc_cx) / len(acc_cx))\n",
    "    avg_cy = int(sum(acc_cy) / len(acc_cy))\n",
    "    return [avg_cx, avg_cy]\n",
    "\n",
    "try:\n",
    "    with open(CONFIG_PATH, 'r') as fp:\n",
    "        points_of_interest = json.load(fp)\n",
    "except FileNotFoundError:\n",
    "    with open(CONFIG_PATH, 'w+') as fp:\n",
    "        fp.write(\"[]\")\n",
    "        points_of_interest = []\n",
    "\n",
    "drawing = False\n",
    "ix,iy = -1,-1\n",
    "def draw_rectangle(event, x, y, flags, param):\n",
    "    global drawing, rect_start, points_of_interest\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        drawing = True\n",
    "        rect_start = (x, y)\n",
    "    elif event == cv2.EVENT_MOUSEMOVE:\n",
    "        if drawing:\n",
    "            img_copy = img.copy()\n",
    "            cv2.rectangle(img_copy, rect_start, (x, y), (0, 255, 0), 1)\n",
    "            cv2.imshow(\"TOP CIENCIA DE DADOS I\", img_copy)\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        drawing = False\n",
    "        rect_end = (x, y)\n",
    "        cv2.rectangle(img, rect_start, rect_end, (0, 255, 0), 1)\n",
    "        cv2.imshow(\"TOP CIENCIA DE DADOS I\", img)\n",
    "        threading.Thread(target=get_new_object, args=(rect_start, rect_end)).start()        \n",
    "\n",
    "cap = cv2.VideoCapture(CAM_NUMBER)\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands()\n",
    "mp_draw = mp.solutions.drawing_utils\n",
    "\n",
    "cv2.namedWindow(\"TOP CIENCIA DE DADOS I\")\n",
    "cv2.setMouseCallback(\"TOP CIENCIA DE DADOS I\", draw_rectangle)\n",
    "currentframe = 0\n",
    "while True:\n",
    "    hands_positions = []\n",
    "    matches = []\n",
    "\n",
    "    success, img = cap.read()\n",
    "\n",
    "    img = cv2.flip(img, 1)\n",
    "    imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    results = hands.process(imgRGB)\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        hands_positions = []  # reset list\n",
    "        for handLms in results.multi_hand_landmarks:\n",
    "            acc_cx = []\n",
    "            acc_cy = []\n",
    "            for id, lm in enumerate(handLms.landmark):\n",
    "                h, w, c = img.shape\n",
    "                cx, cy = int(lm.x * w), int(lm.y * h)\n",
    "                acc_cx, acc_cy = acc_cx + [cx], acc_cy + [cy]\n",
    "\n",
    "            (avg_cx, avg_cy) = mid_point(acc_cx, acc_cy)\n",
    "            cv2.circle(img, (avg_cx, avg_cy), 2, (255, 0, 0), 20, cv2.FILLED)\n",
    "            hands_positions.append([avg_cx, avg_cy])\n",
    "            mp_draw.draw_landmarks(img, handLms, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "    for location in points_of_interest:\n",
    "        color = (200, 0, 0)\n",
    "        for hand_position in hands_positions:\n",
    "            if location[\"point_1\"][0] < hand_position[0] < location[\"point_2\"][0] and \\\n",
    "                location[\"point_1\"][1] < hand_position[1] < location[\"point_2\"][1]:\n",
    "                matches.append(location[\"name\"])\n",
    "                color = (0, 200, 0)\n",
    "\n",
    "                name = './data/frame/' + str(location[\"name\"]) + \"_\" + str(currentframe) + '.jpg'\n",
    "                roi = img[166:959,24:1433]\n",
    "                if currentframe % 5 == 0:\n",
    "                    cv2.imwrite(name, roi)\n",
    "                currentframe += 1\n",
    "\n",
    "        title_position = (int(location[\"point_1\"][0]), int(location[\"point_1\"][1] - 10))\n",
    "        cv2.putText(img, location[\"name\"], title_position, cv2.QT_FONT_NORMAL, 0.8, color, 1)\n",
    "        cv2.rectangle(img, location[\"point_1\"], location[\"point_2\"], color, 1)\n",
    "\n",
    "    img = cv2.copyMakeBorder(img, TOP_BORDER_HEIGHT, 0, 0, 0, cv2.BORDER_CONSTANT, value=(0, 0, 0))\n",
    "    cv2.putText(img, \" \".join(matches), (10, 40), cv2.QT_FONT_NORMAL, 0.7, (0, 255, 0), 1)\n",
    "    cv2.putText(img, \"Use o mouse para desenhar um retangulo em volta do objeto\", (10, 15), cv2.QT_FONT_NORMAL, 0.5, (100, 100, 100), 1)\n",
    "    cv2.putText(img, str(hands_positions or \"\"), (10, 65), cv2.QT_FONT_NORMAL, 0.7, (0, 255, 0), 1)\n",
    "\n",
    "    cv2.imshow(\"TOP CIENCIA DE DADOS I\", img)\n",
    "\n",
    "    if new_object is not None:\n",
    "        if new_object[\"name\"] is not None and new_object[\"name\"].strip() != \"\":\n",
    "            points_of_interest.append(new_object)\n",
    "            with open(CONFIG_PATH, \"w\") as fp:\n",
    "                json.dump(points_of_interest, fp=fp, indent=4)\n",
    "            print(f\"New object {new_object} added.\")\n",
    "        new_object = None\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord(\"q\") or cv2.getWindowProperty(\"TOP CIENCIA DE DADOS I\", cv2.WND_PROP_VISIBLE) < 1:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLO  6b38221 Python-3.11.9 torch-2.3.0+cpu CPU\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model summary (fused): 168 layers, 11127906 parameters, 0 gradients, 28.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 D:\\PUC\\Topicos_Ciencia_Dados_VisaoComputacional\\picking\\data\\frame\\led_ext_4.jpg: 384x640 3 leds, 106.5ms\n",
      "Speed: 1.0ms pre-process, 106.5ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9\\runs\\detect\\exp4\u001b[0m\n",
      "1 labels saved to yolov9\\runs\\detect\\exp4\\labels\n",
      "YOLO  6b38221 Python-3.11.9 torch-2.3.0+cpu CPU\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model summary (fused): 168 layers, 11127906 parameters, 0 gradients, 28.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 D:\\PUC\\Topicos_Ciencia_Dados_VisaoComputacional\\picking\\data\\frame\\led_resistor_ext.jpg: 416x640 1 botao, 1 led, 1 resistor, 95.5ms\n",
      "Speed: 1.0ms pre-process, 95.5ms inference, 0.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov9\\runs\\detect\\exp5\u001b[0m\n",
      "1 labels saved to yolov9\\runs\\detect\\exp5\\labels\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "for file in Path(\"data/frame\").glob(\"*.jpg\"):\n",
    "    run_yolo_detect(weights=\"yolo_weights/weights/last.pt\",\n",
    "                    source=str(file),\n",
    "                    device=\"cpu\",\n",
    "                    conf_thres=0.1,\n",
    "                    save_txt=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
